{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a28efb2",
   "metadata": {},
   "source": [
    "# ğŸ“– Markdown æ¸…æ´—è„šæœ¬\n",
    "\n",
    "å°†OCRè¾“å‡ºçš„åŸå§‹MarkdownæŒ‰ç…§ç« èŠ‚ç»“æ„é‡æ–°ç»„ç»‡ï¼ŒåŒæ—¶ä¿ç•™é¡µç ä¿¡æ¯ç”¨äºRAG/çŸ¥è¯†åº“å»ºç«‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d421cdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ç›®å½•: output_markdown\n",
      "è¾“å‡ºç›®å½•: cleaned_md\n",
      "åˆ›å»ºè¾“å‡ºç›®å½•: cleaned_md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "# é…ç½®è·¯å¾„\n",
    "input_dir = Path('output_markdown')\n",
    "output_dir = Path('cleaned_md')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"è¾“å…¥ç›®å½•: {input_dir}\")\n",
    "print(f\"è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "print(f\"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9e8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "class MarkdownCleaner:\n",
    "    \"\"\"\n",
    "    é’ˆå¯¹ EPUB -> pandoc -> Markdown åœºæ™¯çš„æ¸…æ´—å™¨ï¼ˆå…¼å®¹ä½ åŸæ¥ OCR æ¸…æ´—æ€è·¯ï¼‰\n",
    "    ç›®æ ‡ï¼š\n",
    "    1) æ¸…ç† pandoc/calibre æ®‹ç•™ HTML ä¸é”šç‚¹å™ªéŸ³\n",
    "    2) ç»Ÿä¸€ superscript å¼•ç”¨ï¼ˆå¦‚ <sup>...</sup>ï¼‰ä¸º [^n]\n",
    "    3) ä¿®å¤è¢«é”™è¯¯æ–­å¼€çš„è¡Œï¼ˆé¿å…æŠŠæ ‡é¢˜/åˆ—è¡¨/ä»£ç è¯¯å¹¶ï¼‰\n",
    "    4) ä¿ç•™ Markdown æ ‡é¢˜ç»“æ„ï¼Œä¾¿äºåç»­ AI è¯†åˆ«\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_path: str,\n",
    "        output_path: Optional[str] = None,\n",
    "        remove_title_lines: bool = True,\n",
    "        convert_sup_to_footnote: bool = True,  # True => [^n], False => [n]\n",
    "    ):\n",
    "        self.input_path = Path(input_path)\n",
    "        if output_path is None:\n",
    "            self.output_path = self.input_path.with_name(self.input_path.stem + \"_cleaned.md\")\n",
    "        else:\n",
    "            self.output_path = Path(output_path)\n",
    "\n",
    "        self.remove_title_lines = remove_title_lines\n",
    "        self.convert_sup_to_footnote = convert_sup_to_footnote\n",
    "\n",
    "        # ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾¿äºä½ åšè´¨é‡å›å½’\n",
    "        self.stats: Dict[str, int] = {\n",
    "            \"html_tags_removed\": 0,\n",
    "            \"sup_refs_normalized\": 0,\n",
    "            \"index_anchors_removed\": 0,\n",
    "            \"escaped_brackets_fixed\": 0,\n",
    "            \"lines_merged\": 0,\n",
    "            \"book_title_lines_removed\": 0,\n",
    "        }\n",
    "\n",
    "        # ä½ åŸ notebook è‹¥æœ‰å›ºå®šä¹¦ååˆ—è¡¨ï¼Œå¯åœ¨è¿™é‡Œè¡¥å……\n",
    "        self.book_title_patterns = [\n",
    "            r\"^\\s*ã€Š[^ã€‹]+ã€‹\\s*$\",\n",
    "            r\"^\\s*[\\u4e00-\\u9fffA-Za-z0-9Â·\\s]{2,60}\\s*[-â€”]\\s*[\\u4e00-\\u9fffA-Za-z0-9Â·\\s]{2,60}\\s*$\",\n",
    "        ]\n",
    "\n",
    "    # -----------------------------\n",
    "    # åŸºç¡€å·¥å…·\n",
    "    # -----------------------------\n",
    "    @staticmethod\n",
    "    def _normalize_unicode(text: str) -> str:\n",
    "        # ç»Ÿä¸€å…¨åŠè§’å…¼å®¹å­—ç¬¦ï¼Œå‡å°‘å¥‡æ€ªç¬¦å·\n",
    "        return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    @staticmethod\n",
    "    def _collapse_spaces(text: str) -> str:\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "        return text.strip()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) pandoc å¼•ç”¨å™ªéŸ³æ¸…æ´—\n",
    "    # -----------------------------\n",
    "    def normalize_pandoc_refs(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        å¤„ç†ï¼š\n",
    "        - <sup>...</sup> å†…éƒ¨çš„å„ç§ span/link/è½¬ä¹‰ç¬¦\n",
    "        - (#index_split_xxx.html_fileposxxxxx)\n",
    "        - \\\\[7\\\\] -> [7]\n",
    "        \"\"\"\n",
    "        s = text\n",
    "\n",
    "        # HTML å®ä½“\n",
    "        s = s.replace(\"&nbsp;\", \" \").replace(\"&amp;\", \"&\")\n",
    "\n",
    "        # å…ˆæ›¿æ¢è½¬ä¹‰æ–¹æ‹¬å·ï¼ˆé¿å…åç»­åŒ¹é…ä¸åˆ°ï¼‰\n",
    "        before = s\n",
    "        s = s.replace(r\"\\[\", \"[\").replace(r\"\\]\", \"]\")\n",
    "        if s != before:\n",
    "            self.stats[\"escaped_brackets_fixed\"] += 1\n",
    "\n",
    "        # å» spanï¼ˆä¿ç•™å†…å®¹ï¼‰\n",
    "        before = s\n",
    "        s = re.sub(r\"</?span[^>]*>\", \"\", s, flags=re.IGNORECASE)\n",
    "        if s != before:\n",
    "            # è®¡æ•°ç²—ç•¥æŒ‰â€œå‘ç”Ÿè¿‡ä¸€æ¬¡æ›¿æ¢â€è®°\n",
    "            self.stats[\"html_tags_removed\"] += 1\n",
    "\n",
    "        # sup -> [^n] / [n]\n",
    "        def _sup_to_ref(m):\n",
    "            raw = m.group(1)\n",
    "\n",
    "            # å»æ‰ markdown é“¾æ¥ç»“æ„ [xxx](url)ï¼Œåªç•™æ–‡æœ¬éƒ¨åˆ†\n",
    "            raw = re.sub(r\"\\[([^\\]]*)\\]\\([^)]+\\)\", r\"\\1\", raw)\n",
    "\n",
    "            # å»é™¤æ®‹ç•™ HTML æ ‡ç­¾\n",
    "            raw = re.sub(r\"</?[^>]+>\", \"\", raw)\n",
    "\n",
    "            # æå–æ•°å­—\n",
    "            num = re.search(r\"\\[(\\d+)\\]|\\b(\\d+)\\b\", raw)\n",
    "            if num:\n",
    "                n = num.group(1) or num.group(2)\n",
    "                self.stats[\"sup_refs_normalized\"] += 1\n",
    "                if self.convert_sup_to_footnote:\n",
    "                    return f\"[^{n}]\"\n",
    "                return f\"[{n}]\"\n",
    "            # æ— æ³•æå–ç¼–å·åˆ™åˆ é™¤ sup å—\n",
    "            self.stats[\"sup_refs_normalized\"] += 1\n",
    "            return \"\"\n",
    "\n",
    "        s = re.sub(\n",
    "            r\"<sup[^>]*>(.*?)</sup>\",\n",
    "            _sup_to_ref,\n",
    "            s,\n",
    "            flags=re.IGNORECASE | re.DOTALL,\n",
    "        )\n",
    "\n",
    "        # åˆ é™¤ pandoc/calibre ç”Ÿæˆçš„ index_split é”šç‚¹\n",
    "        before = s\n",
    "        s = re.sub(r\"\\(#index_split_[^)]+\\)\", \"\", s, flags=re.IGNORECASE)\n",
    "        if s != before:\n",
    "            self.stats[\"index_anchors_removed\"] += 1\n",
    "\n",
    "        return s\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) HTML å»å™ªï¼ˆä¿ç•™æ­£æ–‡ï¼‰\n",
    "    # -----------------------------\n",
    "    def strip_html_keep_text(self, text: str) -> str:\n",
    "        s = text\n",
    "\n",
    "        # script/style æ•´å—åˆ \n",
    "        before = s\n",
    "        s = re.sub(r\"<script[^>]*>.*?</script>\", \"\", s, flags=re.IGNORECASE | re.DOTALL)\n",
    "        s = re.sub(r\"<style[^>]*>.*?</style>\", \"\", s, flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "        # å…¶ä»–æ ‡ç­¾åˆ æ‰ï¼Œä»…ä¿ç•™æ–‡æœ¬\n",
    "        s2 = re.sub(r\"</?[^>]+>\", \"\", s)\n",
    "        if s2 != s:\n",
    "            self.stats[\"html_tags_removed\"] += 1\n",
    "        s = s2\n",
    "\n",
    "        if s != before:\n",
    "            pass\n",
    "\n",
    "        return self._collapse_spaces(s)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) æ–­è¡Œä¿®å¤ï¼ˆpandocå¢å¼ºç‰ˆï¼‰\n",
    "    # -----------------------------\n",
    "    def fix_line_breaks_pandoc(self, text: str) -> str:\n",
    "        lines = text.split(\"\\n\")\n",
    "        out: List[str] = []\n",
    "        i = 0\n",
    "\n",
    "        hard_break_pat = re.compile(\n",
    "            r\"^\\s*(#{1,6}\\s|[-*+]\\s|\\d+\\.\\s|```|>\\s|---+$|\\|)\"\n",
    "        )\n",
    "\n",
    "        # å½“å‰è¡Œæœ«å°¾è‹¥æ˜¯æ˜ç¡®å¥ç»ˆï¼Œä¸å»ºè®®ä¸ä¸‹ä¸€è¡Œåˆå¹¶\n",
    "        end_punct = re.compile(r\"[ã€‚ï¼ï¼Ÿ!?ï¼›;ï¼š:]$|[.?!]$|[â€\\\"â€™']$\")\n",
    "\n",
    "        # ä¸‹ä¸€è¡Œè‹¥ä»¥ä¸‹æ¨¡å¼å¼€å¤´ï¼Œé€šå¸¸æ˜¯ç»­å¥\n",
    "        likely_cont = re.compile(r\"^[a-z0-9ï¼ˆ(â€œ\\\"'ã€Šã€\\u4e00-\\u9fff]\")\n",
    "\n",
    "        while i < len(lines):\n",
    "            cur = lines[i].rstrip()\n",
    "\n",
    "            if not cur.strip():\n",
    "                out.append(cur)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if i + 1 < len(lines):\n",
    "                nxt = lines[i + 1].lstrip()\n",
    "\n",
    "                cur_not_end = not end_punct.search(cur)\n",
    "                nxt_not_start = not hard_break_pat.match(nxt)\n",
    "                nxt_is_cont = bool(likely_cont.match(nxt))\n",
    "\n",
    "                # é¿å…æŠŠ markdown æ ‡é¢˜è¡Œå¹¶æ‰\n",
    "                cur_is_heading = bool(re.match(r\"^\\s*#{1,6}\\s\", cur))\n",
    "\n",
    "                if (not cur_is_heading) and cur_not_end and nxt_not_start and nxt_is_cont:\n",
    "                    out.append(cur + \" \" + nxt)\n",
    "                    self.stats[\"lines_merged\"] += 1\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            out.append(cur)\n",
    "            i += 1\n",
    "\n",
    "        s = \"\\n\".join(out)\n",
    "        return self._collapse_spaces(s)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) å¯é€‰ï¼šåˆ é™¤ç–‘ä¼¼â€œä¹¦å/é¡µçœ‰é¡µè„šâ€ç‹¬ç«‹è¡Œ\n",
    "    # -----------------------------\n",
    "    def remove_book_titles_from_content(self, text: str) -> str:\n",
    "        if not self.remove_title_lines:\n",
    "            return text\n",
    "\n",
    "        out = []\n",
    "        for line in text.split(\"\\n\"):\n",
    "            stripped = line.strip()\n",
    "            if not stripped:\n",
    "                out.append(line)\n",
    "                continue\n",
    "\n",
    "            matched = any(re.search(pat, stripped) for pat in self.book_title_patterns)\n",
    "            if matched:\n",
    "                self.stats[\"book_title_lines_removed\"] += 1\n",
    "                continue\n",
    "            out.append(line)\n",
    "\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) å•å—æ¸…æ´—æµæ°´çº¿\n",
    "    # -----------------------------\n",
    "    def clean_block_text(self, text: str) -> str:\n",
    "        s = self._normalize_unicode(text)\n",
    "        s = self.normalize_pandoc_refs(s)        # å…ˆåšå¼•ç”¨å½’ä¸€åŒ–\n",
    "        s = self.strip_html_keep_text(s)         # å»æ ‡ç­¾\n",
    "        s = self.fix_line_breaks_pandoc(s)       # ä¿®æ–­è¡Œ\n",
    "        s = self.remove_book_titles_from_content(s)\n",
    "        s = self._collapse_spaces(s)\n",
    "        return s\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6) æŒ‰è¡Œè§£æï¼šå°½é‡ä¿ç•™ Markdown ç»“æ„\n",
    "    # -----------------------------\n",
    "    def parse_markdown(self, raw_text: str) -> str:\n",
    "        \"\"\"\n",
    "        è§„åˆ™ï¼š\n",
    "        - æ ‡é¢˜è¡Œï¼ˆ#ï¼‰åŸæ ·ä¿ç•™ï¼ˆä»…åšè½»é‡è§„èŒƒï¼‰\n",
    "        - ä»£ç å— ``` åŸæ ·ä¿ç•™ï¼Œä¸åšæ­£æ–‡æ¸…æ´—\n",
    "        - æ™®é€šæ®µè½ç´¯è®¡æˆ block åç»Ÿä¸€ clean_block_text\n",
    "        \"\"\"\n",
    "        lines = raw_text.split(\"\\n\")\n",
    "        out: List[str] = []\n",
    "\n",
    "        in_code_block = False\n",
    "        buf: List[str] = []\n",
    "\n",
    "        def flush_buf():\n",
    "            nonlocal buf\n",
    "            if not buf:\n",
    "                return\n",
    "            block = \"\\n\".join(buf).strip(\"\\n\")\n",
    "            if block.strip():\n",
    "                cleaned = self.clean_block_text(block)\n",
    "                if cleaned:\n",
    "                    out.append(cleaned)\n",
    "            buf = []\n",
    "\n",
    "        for line in lines:\n",
    "            # code fence\n",
    "            if line.strip().startswith(\"```\"):\n",
    "                if in_code_block:\n",
    "                    # ç»“æŸä»£ç å—\n",
    "                    out.append(line.rstrip())\n",
    "                    in_code_block = False\n",
    "                else:\n",
    "                    # å¼€å§‹ä»£ç å—ï¼šå…ˆå†²åˆ·æ­£æ–‡ buffer\n",
    "                    flush_buf()\n",
    "                    out.append(line.rstrip())\n",
    "                    in_code_block = True\n",
    "                continue\n",
    "\n",
    "            if in_code_block:\n",
    "                out.append(line.rstrip(\"\\n\"))\n",
    "                continue\n",
    "\n",
    "            # æ ‡é¢˜è¡Œï¼šå…ˆå†²åˆ· bufferï¼Œå†å†™æ ‡é¢˜\n",
    "            if re.match(r\"^\\s*#{1,6}\\s\", line):\n",
    "                flush_buf()\n",
    "                out.append(self._collapse_spaces(line))\n",
    "                continue\n",
    "\n",
    "            # ç©ºè¡Œï¼šç»“æŸå½“å‰æ®µ\n",
    "            if not line.strip():\n",
    "                flush_buf()\n",
    "                out.append(\"\")\n",
    "                continue\n",
    "\n",
    "            # æ™®é€šæ­£æ–‡ç´¯ç§¯\n",
    "            buf.append(line.rstrip())\n",
    "\n",
    "        flush_buf()\n",
    "\n",
    "        # æ”¶å°¾ï¼šå‹ç¼©å¤šç©ºè¡Œ\n",
    "        result = \"\\n\".join(out)\n",
    "        result = re.sub(r\"\\n{3,}\", \"\\n\\n\", result).strip() + \"\\n\"\n",
    "        return result\n",
    "\n",
    "    # -----------------------------\n",
    "    # 7) æ–‡ä»¶å…¥å£\n",
    "    # -----------------------------\n",
    "    def clean_file(self) -> Tuple[Path, Dict[str, int]]:\n",
    "        if not self.input_path.exists():\n",
    "            raise FileNotFoundError(f\"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {self.input_path}\")\n",
    "\n",
    "        raw = self.input_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        cleaned = self.parse_markdown(raw)\n",
    "        self.output_path.write_text(cleaned, encoding=\"utf-8\")\n",
    "\n",
    "        return self.output_path, self.stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce023ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ç›®å½•: output_markdown\n",
      "è¾“å‡ºç›®å½•: cleaned_md\n",
      "\n",
      "æ‰¾åˆ° 5 ä¸ªMarkdownæ–‡ä»¶\n",
      "\n",
      "============================================================\n",
      "å¤„ç†: ä¸­å›½å·¨å€ºï¼šç»æµå¥‡è¿¹çš„æ ¹æºä¸æœªæ¥ (åˆ˜æµ·å½±) (Z-Library).md\n",
      "============================================================\n",
      "âœ“ å®Œæˆ: ä¸­å›½å·¨å€ºï¼šç»æµå¥‡è¿¹çš„æ ¹æºä¸æœªæ¥ (åˆ˜æµ·å½±) (Z-Library).md\n",
      "  ç»Ÿè®¡: sup_refs=0, anchors=0, html=0, merged=3124\n",
      "\n",
      "============================================================\n",
      "å¤„ç†: äººåœ°ä¹‹é—´ï¼šä¸­å›½å¢é•¿æ¨¡å¼ä¸‹çš„åŸä¹¡åœŸåœ°æ”¹é© (é™¶ç„¶) (Z-Library).md\n",
      "============================================================\n",
      "âœ“ å®Œæˆ: äººåœ°ä¹‹é—´ï¼šä¸­å›½å¢é•¿æ¨¡å¼ä¸‹çš„åŸä¹¡åœŸåœ°æ”¹é© (é™¶ç„¶) (Z-Library).md\n",
      "  ç»Ÿè®¡: sup_refs=0, anchors=0, html=0, merged=5034\n",
      "\n",
      "============================================================\n",
      "å¤„ç†: å½“ä»£ä¸­å›½æ”¿åºœä¸æ”¿æ²» (æ™¯è·ƒè¿› é™ˆæ˜æ˜ è‚–æ»¨) (Z-Library).md\n",
      "============================================================\n",
      "âœ“ å®Œæˆ: å½“ä»£ä¸­å›½æ”¿åºœä¸æ”¿æ²» (æ™¯è·ƒè¿› é™ˆæ˜æ˜ è‚–æ»¨) (Z-Library).md\n",
      "  ç»Ÿè®¡: sup_refs=0, anchors=0, html=0, merged=5031\n",
      "\n",
      "============================================================\n",
      "å¤„ç†: å½“ä»£ä¸­å›½çš„å›½å®¶ä¸ç¤¾ä¼šå…³ç³» (å‘¨é›ªå…‰ ä¸»ç¼–) (Z-Library).md\n",
      "============================================================\n",
      "âœ“ å®Œæˆ: å½“ä»£ä¸­å›½çš„å›½å®¶ä¸ç¤¾ä¼šå…³ç³» (å‘¨é›ªå…‰ ä¸»ç¼–) (Z-Library).md\n",
      "  ç»Ÿè®¡: sup_refs=0, anchors=0, html=5, merged=3119\n",
      "\n",
      "============================================================\n",
      "å¤„ç†: æ–°ä¸­å›½è´¢æ”¿é‡‘èåˆ¶åº¦å˜è¿äº‹ä»¶è§£è¯» (é™ˆé›¨éœ² éƒ­åº†æ—º) (Z-Library).md\n",
      "============================================================\n",
      "âœ“ å®Œæˆ: æ–°ä¸­å›½è´¢æ”¿é‡‘èåˆ¶åº¦å˜è¿äº‹ä»¶è§£è¯» (é™ˆé›¨éœ² éƒ­åº†æ—º) (Z-Library).md\n",
      "  ç»Ÿè®¡: sup_refs=0, anchors=0, html=0, merged=9471\n",
      "\n",
      "\n",
      "============================================================\n",
      "æ‰¹å¤„ç†ç»“æŸ\n",
      "============================================================\n",
      "æˆåŠŸ: 5\n",
      "å¤±è´¥: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "# è¿™é‡Œå‡è®¾ MarkdownCleaner ç±»å·²ç»åœ¨å‰ä¸€ä¸ª cell å®šä¹‰å¹¶æ‰§è¡Œè¿‡\n",
    "# å¦‚æœæ²¡æœ‰ï¼Œè¯·å…ˆè¿è¡Œå®šä¹‰ç±»çš„é‚£ä¸ª cell\n",
    "\n",
    "def batch_clean_markdown(\n",
    "    input_dir=\"output_markdown\",\n",
    "    output_dir=\"cleaned_md\",\n",
    "    remove_title_lines=True,\n",
    "    convert_sup_to_footnote=True,\n",
    "):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    print(f\"è¾“å…¥ç›®å½•: {input_dir}\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "\n",
    "    if not input_dir.exists():\n",
    "        print(f\"âœ— è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}\")\n",
    "\n",
    "    md_files = sorted(list(input_dir.glob(\"*.md\")))\n",
    "    print(f\"\\næ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶\\n\")\n",
    "\n",
    "    success, failed = 0, 0\n",
    "    fail_list = []\n",
    "\n",
    "    for md_file in md_files:\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"å¤„ç†: {md_file.name}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        try:\n",
    "            out_file = output_dir / md_file.name\n",
    "\n",
    "            # å…³é”®ï¼šæ¯ä¸ªæ–‡ä»¶éƒ½å®ä¾‹åŒ– cleaner\n",
    "            cleaner = MarkdownCleaner(\n",
    "                input_path=str(md_file),\n",
    "                output_path=str(out_file),\n",
    "                remove_title_lines=remove_title_lines,\n",
    "                convert_sup_to_footnote=convert_sup_to_footnote,\n",
    "            )\n",
    "\n",
    "            out_path, stats = cleaner.clean_file()\n",
    "\n",
    "            print(f\"âœ“ å®Œæˆ: {out_path.name}\")\n",
    "            print(\n",
    "                \"  ç»Ÿè®¡: \"\n",
    "                f\"sup_refs={stats.get('sup_refs_normalized',0)}, \"\n",
    "                f\"anchors={stats.get('index_anchors_removed',0)}, \"\n",
    "                f\"html={stats.get('html_tags_removed',0)}, \"\n",
    "                f\"merged={stats.get('lines_merged',0)}\"\n",
    "            )\n",
    "            success += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            fail_list.append((md_file.name, str(e)))\n",
    "            print(f\"âœ— å¤„ç†å¤±è´¥: {e}\")\n",
    "            # å¦‚éœ€è¯¦ç»†æ ˆå¯æ‰“å¼€ä¸‹ä¸€è¡Œ\n",
    "            # traceback.print_exc()\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ‰¹å¤„ç†ç»“æŸ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"æˆåŠŸ: {success}\")\n",
    "    print(f\"å¤±è´¥: {failed}\")\n",
    "\n",
    "    if fail_list:\n",
    "        print(\"\\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:\")\n",
    "        for i, (fname, err) in enumerate(fail_list, 1):\n",
    "            print(f\"{i}. {fname} -> {err}\")\n",
    "\n",
    "# è¿è¡Œ\n",
    "batch_clean_markdown(\n",
    "    input_dir=\"output_markdown\",\n",
    "    output_dir=\"cleaned_md\",\n",
    "    remove_title_lines=True,\n",
    "    convert_sup_to_footnote=True,  # True => [^7], False => [7]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
